{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, I am going to build a model and generate predictions for the (DonorsChoose.org Application Screening Kaggle competition)[https://www.kaggle.com/c/donorschoose-application-screening].\n",
    "\n",
    "For the sake of brevity, I will concentrate on using 2 particular machine learning algorithms - one for the text features and another for the structured data. I have settled on XGBoost for the former because it tends to perform well on structured data, which we have here, and I want to gain more experience using it. I will use Multinomial Naive Bayes for the text features for simplicity. I have resisted the temptation to over-optimise and focus rather on getting a proof of concept that could be built on further.\n",
    "\n",
    "I ended up achieving an AUC of 0.75409, without doing any parameter tuning or playing around very much with feature engineering. Doing this, as well as being more flexible with my modelling approach (trying different models and specifications) would likely see some improvement. I didn't enter this competition for the competition but for the experience. However, a comparison to the leaderboard provides some context for the model perforance. I submitted my final result after the competition ended but I would have placed 317 out of 581. It's not too bad, considering I didn't do any tuning. Also the top score was 0.83307, which is not *too* far from my score. In a real-world setting, this could be good enough to try out in the field while iterating on it and gathering feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathan/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "\n",
    "sys.path.append('../src/custom-modules')\n",
    "from model_diagnostics import classification_model_cv_results, classification_model_holdout_results\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathan/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/raw/train.csv')\n",
    "test = pd.read_csv('../data/raw/test.csv')\n",
    "resources = pd.read_csv('../data/raw/resources.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Exploration & Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'm going to deal with the `train` dataset. Let's convert `project_submitted_datetime` to datetime off the bat. The other columns seem correctly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                      object\n",
       "teacher_id                                              object\n",
       "teacher_prefix                                          object\n",
       "school_state                                            object\n",
       "project_submitted_datetime                      datetime64[ns]\n",
       "project_grade_category                                  object\n",
       "project_subject_categories                              object\n",
       "project_subject_subcategories                           object\n",
       "project_title                                           object\n",
       "project_essay_1                                         object\n",
       "project_essay_2                                         object\n",
       "project_essay_3                                         object\n",
       "project_essay_4                                         object\n",
       "project_resource_summary                                object\n",
       "teacher_number_of_previously_posted_projects             int64\n",
       "project_is_approved                                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['project_submitted_datetime'] = pd.to_datetime(train['project_submitted_datetime'])\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look for missing data. There are only 3 columns with missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "teacher_prefix          4\n",
       "project_essay_3    175706\n",
       "project_essay_4    175706\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = train.isnull().sum()\n",
    "missing_values[missing_values>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect for all data for `project_essay_3` and `project_essay_4` to be missing since they were removed from May 17, 2016. We can see this in the dataset and no missing values for these columns thereafter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 2016-05-17:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6345 entries, 18 to 182079\n",
      "Data columns (total 2 columns):\n",
      "project_essay_3    6345 non-null object\n",
      "project_essay_4    6345 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 148.7+ KB\n",
      "None\n",
      "\n",
      "After 2016-05-17:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 175436 entries, 0 to 182078\n",
      "Data columns (total 2 columns):\n",
      "project_essay_3    0 non-null object\n",
      "project_essay_4    0 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Before 2016-05-17:\\n')\n",
    "print(train.loc[train['project_submitted_datetime'] <= '2016-05-17', ['project_essay_3', 'project_essay_4']].info())\n",
    "print('\\nAfter 2016-05-17:\\n')\n",
    "print(train.loc[train['project_submitted_datetime'] > '2016-05-18', ['project_essay_3', 'project_essay_4']].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 4 missing values for `teacher_prefix` so I'm going to set them to 'MISSING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['teacher_prefix'] = train['teacher_prefix'].fillna('MISSING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peak at the numerical data. We can see that about 85% of the projects are actually approved. This is quite an unbalanced dataset. The metric that we will be using to validate the model, AUC, is unaffected by class imbalance but dealing with it may improve the performance of our model. I tried oversampling the minory class but it didn't make a difference in my case. But perhaps other methods (such as creating a synthetic sample) could produce more fruitful results. \n",
    "\n",
    "Something else that's noticable is the maximum of `teacher_number_of_previously_posted_projects`. Although it has a median of 2 and an upper quartile of 9, the max is an impressive 451."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       teacher_number_of_previously_posted_projects  project_is_approved\n",
      "count                                 182080.000000        182080.000000\n",
      "mean                                      11.237055             0.847682\n",
      "std                                       28.016086             0.359330\n",
      "min                                        0.000000             0.000000\n",
      "25%                                        0.000000             1.000000\n",
      "50%                                        2.000000             1.000000\n",
      "75%                                        9.000000             1.000000\n",
      "max                                      451.000000             1.000000\n"
     ]
    }
   ],
   "source": [
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the tutorial kernal [Getting Started with the DonorsChoose Data Set\n",
    "](https://www.kaggle.com/skleinfeld/getting-started-with-the-donorschoose-data-set) suggests, if we plot `teacher_number_of_previously_posted_projects` with a bin size of 10, we can see that this variable has a very long tail. The fact that it's uniformly distributed after 10 suggets that it's large values shouldn't be treated as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFJCAYAAACCQLQfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqAMAYAiiDgCAIYg6AACG+D9/jeENPKChdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2142f470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['teacher_number_of_previously_posted_projects'].hist(bins=[0,10,450]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the counts for categorical data. We can see that the data is quite clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "teacher_prefix\n",
      "\n",
      "Mrs.       95405\n",
      "Ms.        65066\n",
      "Mr.        17667\n",
      "Teacher     3912\n",
      "Dr.           26\n",
      "MISSING        4\n",
      "Name: teacher_prefix, dtype: int64\n",
      "teacher_prefix\n",
      "Dr.        0.807692\n",
      "MISSING    1.000000\n",
      "Mr.        0.842022\n",
      "Mrs.       0.854085\n",
      "Ms.        0.843052\n",
      "Teacher    0.794223\n",
      "Name: project_is_approved, dtype: float64\n",
      "\n",
      "school_state\n",
      "\n",
      "CA    25695\n",
      "TX    12304\n",
      "NY    12157\n",
      "FL    10359\n",
      "NC     8463\n",
      "IL     7332\n",
      "GA     6636\n",
      "SC     6463\n",
      "MI     5324\n",
      "PA     5093\n",
      "IN     4314\n",
      "MO     4247\n",
      "OH     4139\n",
      "MA     4054\n",
      "LA     3946\n",
      "WA     3903\n",
      "OK     3829\n",
      "NJ     3671\n",
      "AZ     3614\n",
      "VA     3446\n",
      "WI     2983\n",
      "AL     2955\n",
      "TN     2836\n",
      "UT     2814\n",
      "CT     2766\n",
      "MD     2480\n",
      "NV     2297\n",
      "MS     2222\n",
      "KY     2172\n",
      "OR     2119\n",
      "MN     2055\n",
      "CO     1887\n",
      "AR     1757\n",
      "ID     1113\n",
      "IA     1079\n",
      "KS     1060\n",
      "NM      916\n",
      "DC      902\n",
      "HI      869\n",
      "WV      839\n",
      "ME      827\n",
      "DE      589\n",
      "NH      587\n",
      "AK      557\n",
      "SD      494\n",
      "NE      493\n",
      "RI      475\n",
      "MT      384\n",
      "ND      248\n",
      "WY      177\n",
      "VT      139\n",
      "Name: school_state, dtype: int64\n",
      "school_state\n",
      "AK    0.849192\n",
      "AL    0.848393\n",
      "AR    0.832100\n",
      "AZ    0.841727\n",
      "CA    0.856431\n",
      "CO    0.845787\n",
      "CT    0.871294\n",
      "DC    0.812639\n",
      "DE    0.891341\n",
      "FL    0.824500\n",
      "GA    0.834087\n",
      "HI    0.843498\n",
      "IA    0.846154\n",
      "ID    0.841869\n",
      "IL    0.853792\n",
      "IN    0.847937\n",
      "KS    0.852830\n",
      "KY    0.857735\n",
      "LA    0.834009\n",
      "MA    0.860138\n",
      "MD    0.836290\n",
      "ME    0.858525\n",
      "MI    0.844478\n",
      "MN    0.857421\n",
      "MO    0.857547\n",
      "MS    0.843384\n",
      "MT    0.828125\n",
      "NC    0.853480\n",
      "ND    0.866935\n",
      "NE    0.851927\n",
      "NH    0.867121\n",
      "NJ    0.843367\n",
      "NM    0.822052\n",
      "NV    0.856770\n",
      "NY    0.853582\n",
      "OH    0.871467\n",
      "OK    0.834422\n",
      "OR    0.855592\n",
      "PA    0.852543\n",
      "RI    0.844211\n",
      "SC    0.864923\n",
      "SD    0.862348\n",
      "TN    0.851904\n",
      "TX    0.815670\n",
      "UT    0.835110\n",
      "VA    0.855194\n",
      "VT    0.848921\n",
      "WA    0.868050\n",
      "WI    0.845122\n",
      "WV    0.867700\n",
      "WY    0.875706\n",
      "Name: project_is_approved, dtype: float64\n",
      "\n",
      "project_grade_category\n",
      "\n",
      "Grades PreK-2    73890\n",
      "Grades 3-5       61682\n",
      "Grades 6-8       28197\n",
      "Grades 9-12      18311\n",
      "Name: project_grade_category, dtype: int64\n",
      "project_grade_category\n",
      "Grades 3-5       0.853977\n",
      "Grades 6-8       0.843459\n",
      "Grades 9-12      0.835236\n",
      "Grades PreK-2    0.847124\n",
      "Name: project_is_approved, dtype: float64\n",
      "\n",
      "project_subject_categories\n",
      "\n",
      "Literacy & Language                           39257\n",
      "Math & Science                                28555\n",
      "Literacy & Language, Math & Science           24499\n",
      "Health & Sports                               16951\n",
      "Music & The Arts                               8527\n",
      "Special Needs                                  7065\n",
      "Literacy & Language, Special Needs             6685\n",
      "Applied Learning                               6310\n",
      "Math & Science, Literacy & Language            3843\n",
      "Applied Learning, Literacy & Language          3725\n",
      "History & Civics                               3065\n",
      "Math & Science, Special Needs                  3010\n",
      "Literacy & Language, Music & The Arts          2878\n",
      "Math & Science, Music & The Arts               2761\n",
      "Applied Learning, Special Needs                2481\n",
      "Health & Sports, Special Needs                 2368\n",
      "History & Civics, Literacy & Language          2288\n",
      "Warmth, Care & Hunger                          2191\n",
      "Math & Science, Applied Learning               2071\n",
      "Applied Learning, Math & Science               1711\n",
      "Literacy & Language, History & Civics          1315\n",
      "Health & Sports, Literacy & Language           1308\n",
      "Applied Learning, Music & The Arts             1241\n",
      "Math & Science, History & Civics               1087\n",
      "Literacy & Language, Applied Learning          1038\n",
      "Applied Learning, Health & Sports              1018\n",
      "Math & Science, Health & Sports                 697\n",
      "History & Civics, Music & The Arts              544\n",
      "History & Civics, Math & Science                525\n",
      "Special Needs, Music & The Arts                 521\n",
      "Health & Sports, Math & Science                 470\n",
      "History & Civics, Special Needs                 417\n",
      "Applied Learning, History & Civics              303\n",
      "Health & Sports, Applied Learning               297\n",
      "Health & Sports, Music & The Arts               262\n",
      "Music & The Arts, Special Needs                 235\n",
      "Literacy & Language, Health & Sports            127\n",
      "Health & Sports, History & Civics                67\n",
      "History & Civics, Applied Learning               65\n",
      "Special Needs, Health & Sports                   64\n",
      "Special Needs, Warmth, Care & Hunger             35\n",
      "Music & The Arts, Health & Sports                32\n",
      "Health & Sports, Warmth, Care & Hunger           31\n",
      "Music & The Arts, History & Civics               29\n",
      "Literacy & Language, Warmth, Care & Hunger       25\n",
      "Applied Learning, Warmth, Care & Hunger          22\n",
      "Music & The Arts, Applied Learning               21\n",
      "History & Civics, Health & Sports                20\n",
      "Math & Science, Warmth, Care & Hunger            19\n",
      "Music & The Arts, Warmth, Care & Hunger           3\n",
      "History & Civics, Warmth, Care & Hunger           1\n",
      "Name: project_subject_categories, dtype: int64\n",
      "project_subject_categories\n",
      "Applied Learning                              0.814897\n",
      "Applied Learning, Health & Sports             0.813360\n",
      "Applied Learning, History & Civics            0.795380\n",
      "Applied Learning, Literacy & Language         0.861208\n",
      "Applied Learning, Math & Science              0.803624\n",
      "Applied Learning, Music & The Arts            0.809831\n",
      "Applied Learning, Special Needs               0.811769\n",
      "Applied Learning, Warmth, Care & Hunger       0.636364\n",
      "Health & Sports                               0.846794\n",
      "Health & Sports, Applied Learning             0.851852\n",
      "Health & Sports, History & Civics             0.820896\n",
      "Health & Sports, Literacy & Language          0.847859\n",
      "Health & Sports, Math & Science               0.848936\n",
      "Health & Sports, Music & The Arts             0.782443\n",
      "Health & Sports, Special Needs                0.861064\n",
      "Health & Sports, Warmth, Care & Hunger        0.903226\n",
      "History & Civics                              0.831974\n",
      "History & Civics, Applied Learning            0.753846\n",
      "History & Civics, Health & Sports             0.900000\n",
      "History & Civics, Literacy & Language         0.885490\n",
      "History & Civics, Math & Science              0.853333\n",
      "History & Civics, Music & The Arts            0.821691\n",
      "History & Civics, Special Needs               0.815348\n",
      "History & Civics, Warmth, Care & Hunger       0.000000\n",
      "Literacy & Language                           0.869858\n",
      "Literacy & Language, Applied Learning         0.859345\n",
      "Literacy & Language, Health & Sports          0.771654\n",
      "Literacy & Language, History & Civics         0.890494\n",
      "Literacy & Language, Math & Science           0.867219\n",
      "Literacy & Language, Music & The Arts         0.838777\n",
      "Literacy & Language, Special Needs            0.854450\n",
      "Literacy & Language, Warmth, Care & Hunger    0.840000\n",
      "Math & Science                                0.821082\n",
      "Math & Science, Applied Learning              0.832448\n",
      "Math & Science, Health & Sports               0.780488\n",
      "Math & Science, History & Civics              0.858326\n",
      "Math & Science, Literacy & Language           0.861046\n",
      "Math & Science, Music & The Arts              0.827961\n",
      "Math & Science, Special Needs                 0.825581\n",
      "Math & Science, Warmth, Care & Hunger         0.631579\n",
      "Music & The Arts                              0.850006\n",
      "Music & The Arts, Applied Learning            0.714286\n",
      "Music & The Arts, Health & Sports             0.656250\n",
      "Music & The Arts, History & Civics            0.793103\n",
      "Music & The Arts, Special Needs               0.863830\n",
      "Music & The Arts, Warmth, Care & Hunger       0.666667\n",
      "Special Needs                                 0.809483\n",
      "Special Needs, Health & Sports                0.765625\n",
      "Special Needs, Music & The Arts               0.827255\n",
      "Special Needs, Warmth, Care & Hunger          0.771429\n",
      "Warmth, Care & Hunger                         0.921953\n",
      "Name: project_is_approved, dtype: float64\n",
      "\n",
      "project_subject_subcategories\n",
      "\n",
      "Literacy                                        15775\n",
      "Literacy, Mathematics                           13863\n",
      "Literature & Writing, Mathematics                9976\n",
      "Literacy, Literature & Writing                   9282\n",
      "Mathematics                                      9041\n",
      "Literature & Writing                             7474\n",
      "Special Needs                                    7065\n",
      "Health & Wellness                                5924\n",
      "Applied Sciences, Mathematics                    5651\n",
      "Literacy, Special Needs                          4091\n",
      "Applied Sciences                                 4037\n",
      "Gym & Fitness, Health & Wellness                 3864\n",
      "Visual Arts                                      3671\n",
      "ESL, Literacy                                    3624\n",
      "Music                                            2427\n",
      "Literature & Writing, Special Needs              2244\n",
      "Warmth, Care & Hunger                            2191\n",
      "Health & Wellness, Special Needs                 2045\n",
      "Gym & Fitness                                    1960\n",
      "Mathematics, Special Needs                       1948\n",
      "Environmental Science                            1825\n",
      "Team Sports                                      1752\n",
      "Environmental Science, Health & Life Science     1672\n",
      "Applied Sciences, Environmental Science          1663\n",
      "Music, Performing Arts                           1507\n",
      "Early Development                                1498\n",
      "Health & Life Science                            1439\n",
      "Other                                            1397\n",
      "Environmental Science, Mathematics               1387\n",
      "Early Development, Special Needs                 1321\n",
      "                                                ...  \n",
      "Visual Arts, Warmth, Care & Hunger                  3\n",
      "College & Career Prep, Gym & Fitness                3\n",
      "Civics & Government, Foreign Languages              2\n",
      "Financial Literacy, Music                           2\n",
      "Early Development, Economics                        2\n",
      "Parent Involvement, Warmth, Care & Hunger           2\n",
      "Gym & Fitness, Parent Involvement                   2\n",
      "Extracurricular, Foreign Languages                  2\n",
      "Financial Literacy, Health & Wellness               2\n",
      "Nutrition Education, Parent Involvement             2\n",
      "Financial Literacy, Performing Arts                 2\n",
      "Economics, Other                                    2\n",
      "Community Service, Gym & Fitness                    2\n",
      "Community Service, Financial Literacy               2\n",
      "Financial Literacy, Parent Involvement              2\n",
      "ESL, Team Sports                                    2\n",
      "Economics, Extracurricular                          1\n",
      "Civics & Government, Nutrition Education            1\n",
      "Economics, Foreign Languages                        1\n",
      "ESL, Economics                                      1\n",
      "Gym & Fitness, Social Sciences                      1\n",
      "Extracurricular, Warmth, Care & Hunger              1\n",
      "Economics, Music                                    1\n",
      "Parent Involvement, Team Sports                     1\n",
      "Economics, Nutrition Education                      1\n",
      "Financial Literacy, Foreign Languages               1\n",
      "Civics & Government, Parent Involvement             1\n",
      "Music, Nutrition Education                          1\n",
      "History & Geography, Warmth, Care & Hunger          1\n",
      "Gym & Fitness, Warmth, Care & Hunger                1\n",
      "Name: project_subject_subcategories, Length: 407, dtype: int64\n",
      "project_subject_subcategories\n",
      "Applied Sciences                             0.824375\n",
      "Applied Sciences, Character Education        0.835165\n",
      "Applied Sciences, Civics & Government        0.888889\n",
      "Applied Sciences, College & Career Prep      0.838755\n",
      "Applied Sciences, Community Service          0.758621\n",
      "Applied Sciences, ESL                        0.827338\n",
      "Applied Sciences, Early Development          0.802013\n",
      "Applied Sciences, Economics                  0.833333\n",
      "Applied Sciences, Environmental Science      0.800361\n",
      "Applied Sciences, Extracurricular            0.848214\n",
      "Applied Sciences, Financial Literacy         0.846154\n",
      "Applied Sciences, Foreign Languages          0.733333\n",
      "Applied Sciences, Gym & Fitness              0.777778\n",
      "Applied Sciences, Health & Life Science      0.824599\n",
      "Applied Sciences, Health & Wellness          0.837838\n",
      "Applied Sciences, History & Geography        0.824242\n",
      "Applied Sciences, Literacy                   0.838926\n",
      "Applied Sciences, Literature & Writing       0.853237\n",
      "Applied Sciences, Mathematics                0.822863\n",
      "Applied Sciences, Music                      0.888889\n",
      "Applied Sciences, Nutrition Education        0.700000\n",
      "Applied Sciences, Other                      0.842857\n",
      "Applied Sciences, Parent Involvement         0.887850\n",
      "Applied Sciences, Performing Arts            0.844828\n",
      "Applied Sciences, Social Sciences            0.878261\n",
      "Applied Sciences, Special Needs              0.860504\n",
      "Applied Sciences, Team Sports                0.714286\n",
      "Applied Sciences, Visual Arts                0.831925\n",
      "Applied Sciences, Warmth, Care & Hunger      0.333333\n",
      "Character Education                          0.814208\n",
      "                                               ...   \n",
      "Other, Social Sciences                       0.833333\n",
      "Other, Special Needs                         0.818750\n",
      "Other, Team Sports                           1.000000\n",
      "Other, Visual Arts                           0.794118\n",
      "Other, Warmth, Care & Hunger                 0.600000\n",
      "Parent Involvement                           0.750000\n",
      "Parent Involvement, Performing Arts          1.000000\n",
      "Parent Involvement, Social Sciences          0.888889\n",
      "Parent Involvement, Special Needs            0.807018\n",
      "Parent Involvement, Team Sports              1.000000\n",
      "Parent Involvement, Visual Arts              0.924528\n",
      "Parent Involvement, Warmth, Care & Hunger    1.000000\n",
      "Performing Arts                              0.850508\n",
      "Performing Arts, Social Sciences             0.750000\n",
      "Performing Arts, Special Needs               0.857143\n",
      "Performing Arts, Team Sports                 0.714286\n",
      "Performing Arts, Visual Arts                 0.764331\n",
      "Social Sciences                              0.822034\n",
      "Social Sciences, Special Needs               0.835052\n",
      "Social Sciences, Team Sports                 1.000000\n",
      "Social Sciences, Visual Arts                 0.800000\n",
      "Special Needs                                0.809483\n",
      "Special Needs, Team Sports                   0.765625\n",
      "Special Needs, Visual Arts                   0.827255\n",
      "Special Needs, Warmth, Care & Hunger         0.771429\n",
      "Team Sports                                  0.824772\n",
      "Team Sports, Visual Arts                     0.666667\n",
      "Visual Arts                                  0.818850\n",
      "Visual Arts, Warmth, Care & Hunger           0.666667\n",
      "Warmth, Care & Hunger                        0.921953\n",
      "Name: project_is_approved, Length: 407, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find the categorical columns\n",
    "categorical_cols = ['teacher_prefix', 'school_state', 'project_grade_category', 'project_subject_categories', \n",
    "                    'project_subject_subcategories']\n",
    "\n",
    "for c in categorical_cols:\n",
    "    print('\\n{0}\\n'.format(c))\n",
    "    print(train[c].value_counts())\n",
    "    print(train.groupby(c)['project_is_approved'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check for duplicated data. First I'll check for duplicated rows (i.e. all the columns in one row are the same as all of the columns in another). I'll drop a few columns, such as `id`, which we could expect to be different even if all the other columns cause a row to be a duplicate. \n",
    "\n",
    "If we exclude `project_is_approved`, we can see that there are 28 duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consistent - `project_is_approved` is also duplicated\n",
      "\n",
      "False    182057\n",
      "True         23\n",
      "dtype: int64\n",
      "\n",
      "Inconsistent: `project_is_approved` is NOT duplicated\n",
      "\n",
      "False    182052\n",
      "True         28\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\nConsistent - `project_is_approved` is also duplicated\\n')\n",
    "check_for_dupes = train.drop(['id', 'project_submitted_datetime',\n",
    "                                     'teacher_number_of_previously_posted_projects'], axis=1)\n",
    "print(check_for_dupes.duplicated().value_counts())\n",
    "\n",
    "print('\\nInconsistent: `project_is_approved` is NOT duplicated\\n')\n",
    "check_for_dupes = train.drop(['id', 'project_submitted_datetime',\n",
    "                                     'teacher_number_of_previously_posted_projects',\n",
    "                                    'project_is_approved'], axis=1)\n",
    "print(check_for_dupes.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, I'm just going to delete all of these duplicates, since they may bias the results down the line and there are so few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.loc[~train.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these, we would expect the `project_essay` columns to be unique but here we actually do find some duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "project_title\n",
      "\n",
      "False    164282\n",
      "True      17798\n",
      "Name: project_title, dtype: int64\n",
      "\n",
      "project_essay_1\n",
      "\n",
      "False    147689\n",
      "True      34391\n",
      "Name: project_essay_1, dtype: int64\n",
      "\n",
      "project_essay_2\n",
      "\n",
      "False    180984\n",
      "True       1096\n",
      "Name: project_essay_2, dtype: int64\n",
      "\n",
      "project_essay_3\n",
      "\n",
      "False    6359\n",
      "True       15\n",
      "Name: project_essay_3, dtype: int64\n",
      "\n",
      "project_essay_4\n",
      "\n",
      "False    6336\n",
      "True       38\n",
      "Name: project_essay_4, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = ['project_title', 'project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']\n",
    "for c in cols:\n",
    "    print('\\n{0}\\n'.format(c))\n",
    "    print(train[c].dropna().duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not clear what to do with these duplicates. In some cases, the `project_subject_categories` might be different even though the essays are the same. Is this ok? I'm going to keep the duplicates in here for now and put a pin in this - later, I could try to remove the duplicates somehow and see if that improves the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the resources data. We can see that there are a few missing descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description    292\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = resources.isnull().sum()\n",
    "missing_values[missing_values>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these, let's just substitute 'MISSING', since the fact that there the values are missing could be predictive of not being approved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resources['description'] = resources['description'].fillna('MISSING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that looks noteworthy with respect to the numbers is that the minimum price is zero. This is unusual and may reflect incorrect data. I'll leave it for now though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           quantity         price\n",
      "count  1.541272e+06  1.541272e+06\n",
      "mean   2.860509e+00  5.028398e+01\n",
      "std    7.570345e+00  1.447326e+02\n",
      "min    1.000000e+00  0.000000e+00\n",
      "25%    1.000000e+00  7.900000e+00\n",
      "50%    1.000000e+00  1.499000e+01\n",
      "75%    2.000000e+00  3.980000e+01\n",
      "max    8.000000e+02  9.999000e+03\n"
     ]
    }
   ],
   "source": [
    "print(resources.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Further Exploration\n",
    "\n",
    "I am now going to construct some features from the data and perform some additional exploration based on that. I'll proceed in 3 parts:\n",
    "1. Deal with `resources` dataset\n",
    "2. Deal with `train` dataset\n",
    "3. Combined datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Deal with the resources dataset\n",
    "\n",
    "We're told in the data description that many projects will require multiple resources. So the project id (`id`) will be duplicated. I'm going to collape all the data related to a project into a single line to make things easier to work with. For the `description`, I'll just append the words. For the `quantity` and `price`, I'll just find the means. I'll also work out how many resources were requested for each project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>resource_descriptions</th>\n",
       "      <th>resources_count</th>\n",
       "      <th>total_price_max</th>\n",
       "      <th>total_price_mean</th>\n",
       "      <th>total_price_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p000001</td>\n",
       "      <td>Cap Barbell 300 Pound Olympic Set, Grey ; Cap ...</td>\n",
       "      <td>4</td>\n",
       "      <td>522.16</td>\n",
       "      <td>208.407500</td>\n",
       "      <td>833.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p000002</td>\n",
       "      <td>10 Sony Headphones (BUY 9 GET 1 FREE) ; Belkin...</td>\n",
       "      <td>14</td>\n",
       "      <td>134.90</td>\n",
       "      <td>45.020000</td>\n",
       "      <td>630.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p000003</td>\n",
       "      <td>EE820X - Phonemic Awareness Instant Learning C...</td>\n",
       "      <td>4</td>\n",
       "      <td>169.00</td>\n",
       "      <td>74.742500</td>\n",
       "      <td>298.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p000004</td>\n",
       "      <td>A Bad Case of the Giggles Poems That Will Make...</td>\n",
       "      <td>95</td>\n",
       "      <td>401.54</td>\n",
       "      <td>11.854947</td>\n",
       "      <td>1126.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p000005</td>\n",
       "      <td>Fitbit Zip Wireless Activity Tracker, Lime ; F...</td>\n",
       "      <td>4</td>\n",
       "      <td>323.75</td>\n",
       "      <td>175.577500</td>\n",
       "      <td>702.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                              resource_descriptions  \\\n",
       "0  p000001  Cap Barbell 300 Pound Olympic Set, Grey ; Cap ...   \n",
       "1  p000002  10 Sony Headphones (BUY 9 GET 1 FREE) ; Belkin...   \n",
       "2  p000003  EE820X - Phonemic Awareness Instant Learning C...   \n",
       "3  p000004  A Bad Case of the Giggles Poems That Will Make...   \n",
       "4  p000005  Fitbit Zip Wireless Activity Tracker, Lime ; F...   \n",
       "\n",
       "   resources_count  total_price_max  total_price_mean  total_price_sum  \n",
       "0                4           522.16        208.407500           833.63  \n",
       "1               14           134.90         45.020000           630.28  \n",
       "2                4           169.00         74.742500           298.97  \n",
       "3               95           401.54         11.854947          1126.22  \n",
       "4                4           323.75        175.577500           702.31  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resources['total_price'] = resources['price'] * resources['quantity']\n",
    "\n",
    "collapsed_resources = resources.pivot_table(index = ['id'],\n",
    "                                            aggfunc = {'description': [lambda x: x.tolist(), 'count'],\n",
    "                                                       'total_price': ['sum', 'mean', 'max']})\n",
    "collapsed_resources = collapsed_resources.reset_index()\n",
    "\n",
    "# Break multi-level column names into individual lists\n",
    "header_0 = [h[0] for h in collapsed_resources.columns]\n",
    "header_1 = [h[1] for h in collapsed_resources.columns]\n",
    "col_names = list(map('_'.join, zip(header_0, header_1)))\n",
    "\n",
    "collapsed_resources.columns = col_names\n",
    "collapsed_resources = collapsed_resources.rename(columns = {'id_': 'id', 'description_<lambda>': 'resource_descriptions', 'description_count': 'resources_count'})\n",
    "# Get one string combining all descriptions separated by ' ; '\n",
    "collapsed_resources['resource_descriptions'] = collapsed_resources['resource_descriptions'].apply(lambda x: ' ; '.join(map(str, x)))\n",
    "\n",
    "collapsed_resources.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Deal with the train dataset\n",
    "\n",
    "Get word_counts for title and essays. Since the format changed on 17 May 2016, I'll get word-counts for each essay before and after this date, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['after_20160517'] = np.where(train['project_submitted_datetime'] > '2016-05-17', 1, 0)\n",
    "\n",
    "for i, period in enumerate(['before', 'after']):\n",
    "    for col in ['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']:\n",
    "        wordcount_colname = '{0}_wordcount_{1}'.format(col, period)\n",
    "        train.loc[train['after_20160517']==i, \n",
    "                  wordcount_colname] = (train\n",
    "                                        .loc[train['after_20160517']==i, col]\n",
    "                                        .apply(lambda x: len(str(x).split(' '))))\n",
    "        train[wordcount_colname] = train[wordcount_colname].fillna(0)  # Will get null values where there are no words. Fill these with zero.\n",
    "        \n",
    "train['project_title_wordcount'] = (train['project_title'].apply(lambda x: len(str(x).split(' '))))\n",
    "train['project_title_wordcount'] = train['project_title_wordcount'].fillna(0)  # Will get null values where there are no words. Fill these with zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract date from `project_submitted_datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['date'] = train['project_submitted_datetime'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Join the datasets together by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(collapsed_resources, how='inner', on='id', copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split `train` data into training and testing sets for internal validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, testing = train_test_split(train, stratify=train['project_is_approved'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried a few different approaches but the one that I settled on, which gave the best performance given the parameter space, was a stacked model approach:\n",
    "1. Predict probabilities using text features alone\n",
    "2. Predict probabilities using non-text features\n",
    "3. Combine non-text features with predicted probabilities from (1) and (2) above for a final prediction\n",
    "\n",
    "The categories for one project can combine terms that are common to categories in other projects, but in different orders or combinations take \"Math & Science, Literacy & Language\" and \"Literacy & Language, Math & Science\" for instance. If we treat each of these subjects as seperate, or fail to identify the commonalities in them, we might lose relevant information and therefore increase the model bias. Simimlarly for subcategories. I'm going to therefore extract the individual terms using a bag-of-words approach and use those as features in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Multinomial Naive Bayes model to predict probabilities based on text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_essay_1 - before:\n",
      "Area under ROC: 0.511986221664\n",
      "project_essay_2 - before:\n",
      "Area under ROC: 0.529566401341\n",
      "project_essay_3 - before:\n",
      "Area under ROC: 0.630680460519\n",
      "project_essay_4 - before:\n",
      "Area under ROC: 0.562849695108\n",
      "project_essay_1 - after:\n",
      "Area under ROC: 0.562653123377\n",
      "project_essay_2 - after:\n",
      "Area under ROC: 0.678271136375\n",
      "project_title - :\n",
      "Area under ROC: 0.527995611776\n",
      "resource_descriptions - :\n",
      "Area under ROC: 0.612433225988\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Make predictions using text features\n",
    "# ====================================\n",
    "\n",
    "ctv = CountVectorizer(analyzer='word', ngram_range=(1, 3), stop_words = 'english', min_df=0.025)\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Handle the essays (to deal with the different formats)\n",
    "for i, period in enumerate(['before', 'after']):\n",
    "    for col in ['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']:\n",
    "        predict_text(training, \n",
    "                     testing, \n",
    "                     col, \n",
    "                     ctv, \n",
    "                     mnb, \n",
    "                     training['after_20160517']==i, \n",
    "                     testing['after_20160517']==i, \n",
    "                     df_filter_desc=period,\n",
    "                     show_model_results=True, \n",
    "                     fit_model=True)\n",
    "\n",
    "# Handle the text features other than the essays\n",
    "for col in ['project_title', 'resource_descriptions']:\n",
    "    predict_text(\n",
    "        training, \n",
    "        testing, \n",
    "        col, \n",
    "        ctv, \n",
    "        mnb, \n",
    "        show_model_results=True, \n",
    "        fit_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit xgb model using non-text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_classifier = XGBClassifier(seed=0)\n",
    "\n",
    "# Get vectors of word-counts from subject categories and suubcategories\n",
    "ctv = CountVectorizer(analyzer='word', stop_words = 'english')\n",
    "countvecs_train = {}\n",
    "countvecs_train['project_subject_categories'] = ctv.fit_transform(training['project_subject_categories'])\n",
    "countvecs_train['project_subject_subcategories'] = ctv.fit_transform(training['project_subject_subcategories'])\n",
    "countvecs_test = {}\n",
    "countvecs_test['project_subject_categories'] = ctv.fit_transform(testing['project_subject_categories'])\n",
    "countvecs_test['project_subject_subcategories'] = ctv.fit_transform(testing['project_subject_subcategories'])\n",
    "\n",
    "# These are the non-text features to include in xgb model\n",
    "nontext_feature_cols = ['teacher_prefix', 'school_state', 'project_grade_category', 'date', 'after_20160517',\n",
    "                'teacher_number_of_previously_posted_projects', 'project_title_wordcount', \n",
    "                'project_essay_1_wordcount_before', 'project_essay_2_wordcount_before', \n",
    "                'project_essay_3_wordcount_before', 'project_essay_4_wordcount_before', \n",
    "                'project_essay_1_wordcount_after', 'project_essay_2_wordcount_after', \n",
    "                'project_essay_3_wordcount_after', 'project_essay_4_wordcount_after', \n",
    "                'resources_count', 'total_price_sum', 'total_price_max', 'total_price_mean']\n",
    "# nontext_feature_cols = ['teacher_prefix', 'school_state', 'project_grade_category', 'after_20160517',\n",
    "#                 'teacher_number_of_previously_posted_projects', 'project_title_wordcount', \n",
    "#                 'project_essay_1_wordcount_before', 'project_essay_2_wordcount_before', \n",
    "#                 'project_essay_3_wordcount_before', 'project_essay_4_wordcount_before', \n",
    "#                 'project_essay_1_wordcount_after', 'project_essay_2_wordcount_after', \n",
    "#                 'project_essay_3_wordcount_after', 'project_essay_4_wordcount_after', \n",
    "#                 'resources_count', 'total_price_sum', 'total_price_max', 'total_price_mean']\n",
    "# These are the columns we'll dummify in xbg model\n",
    "cols_to_dummify = ['teacher_prefix', 'school_state', 'project_grade_category']\n",
    "# We'll encode these columns in xgb model\n",
    "cols_to_encode = ['date']\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "# Prep training data\n",
    "\n",
    "X_training = training[nontext_feature_cols]\n",
    "X_training = pd.get_dummies(X_training, columns=cols_to_dummify)\n",
    "X_training[cols_to_encode] = X_training[cols_to_encode].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "X_training = np.hstack((np.array(X_training),\n",
    "                     countvecs_train['project_subject_categories'].toarray(),\n",
    "                     countvecs_train['project_subject_subcategories'].toarray()))\n",
    "y_training = training['project_is_approved']\n",
    "\n",
    "\n",
    "# Prep testing data\n",
    "\n",
    "X_testing = testing[nontext_feature_cols]\n",
    "X_testing = pd.get_dummies(X_testing, columns=cols_to_dummify)\n",
    "X_testing[cols_to_encode] = X_testing[cols_to_encode].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "X_testing = np.hstack((np.array(X_testing),\n",
    "                     countvecs_test['project_subject_categories'].toarray(),\n",
    "                     countvecs_test['project_subject_subcategories'].toarray()))\n",
    "y_testing = testing['project_is_approved']\n",
    "\n",
    "xgb_classifier.fit(X_training, y_training)\n",
    "y_pred_proba_xgb = xgb_classifier.predict_proba(X_testing)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine predicted probabilities from xgb model with non-text feature with predicted probabilites from mnb with text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.748059031335\n"
     ]
    }
   ],
   "source": [
    "# Concatenate data (non-text features with predicted probs using text)\n",
    "X_pred_probas = pd.Series(y_pred_proba_xgb)\n",
    "for col in ['project_essay_3_proba_before', 'project_essay_2_proba_after', 'resource_descriptions_proba']:\n",
    "    X_pred_probas = pd.concat([X_pred_probas, testing[col].reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_test_w_probas = np.hstack([X_testing, X_pred_probas])\n",
    "classification_model_cv_results(X_test_w_probas, y_testing, xgb_classifier, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['teacher_prefix'] = test['teacher_prefix'].fillna('MISSING')\n",
    "# test = test.loc[t est['teacher_prefix'].notnull()]\n",
    "test['date'] = pd.to_datetime(test['project_submitted_datetime']).dt.date\n",
    "test['after_20160517'] = np.where(test['project_submitted_datetime'] > '2016-05-17', 1, 0)\n",
    "\n",
    "# Get word counts for text features\n",
    "for i, period in enumerate(['before', 'after']):\n",
    "    for col in ['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']:\n",
    "        wordcount_colname = '{0}_wordcount_{1}'.format(col, period)\n",
    "        test.loc[train['after_20160517']==i, \n",
    "                 wordcount_colname] = (test\n",
    "                                       .loc[test['after_20160517']==i, col]\n",
    "                                       .apply(lambda x: len(str(x).split(' '))))\n",
    "        test[wordcount_colname] = test[wordcount_colname].fillna(0)  # Will get null values where there are no words. Fill these with zero.\n",
    "test['project_title_wordcount'] = test['project_title'].apply(lambda x: len(str(x).split(' ')))\n",
    "test['project_title_wordcount'] = test['project_title_wordcount'].fillna(0)  # Will get null values where there are no words. Fill these with zero.\n",
    "\n",
    "# Join resources data (already been processed when prepping data for modelling)\n",
    "test = test.merge(collapsed_resources, how='inner', on='id')\n",
    "\n",
    "# Count_vectorise train and test sets at the same time to account for words existing in one but not the other\n",
    "ctv = CountVectorizer(analyzer='word', ngram_range=(1, 3), stop_words = 'english')\n",
    "countvecs_train = {}\n",
    "countvecs_test = {}\n",
    "countvecs_train['project_subject_categories'], countvecs_test['project_subject_categories'] = \\\n",
    "    count_vectorise('project_subject_categories', ctv, train, test)\n",
    "countvecs_train['project_subject_subcategories'], countvecs_test['project_subject_subcategories'] = \\\n",
    "    count_vectorise('project_subject_subcategories', ctv, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text features with relatively high AUC by themselves where `project_essay_2` after the change in 17 June, `project_essay_3` before the change, and `resource_descriptions`. I will only include these in the final model. I experimented with adding the others but that didn't seem to make a difference in my case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Make predictions using text features\n",
    "# ====================================\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "ctv = CountVectorizer(analyzer='word', ngram_range=(1, 3), stop_words = 'english', min_df=0.025)\n",
    "\n",
    "# Handle the text features\n",
    "predict_text(train, test, 'project_essay_2', ctv, mnb, train['after_20160517']==1, test['after_20160517']==1, df_filter_desc='after',\n",
    "                    show_model_results=False)\n",
    "predict_text(train, test, 'project_essay_3', ctv, mnb, train['after_20160517']==0, test['after_20160517']==0, df_filter_desc='before',\n",
    "            show_model_results=False)\n",
    "predict_text(train, test, 'resource_descriptions', ctv, mnb, show_model_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# Fit xgb model using non-text features\n",
    "# =====================================\n",
    "\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "nontext_feature_cols = ['teacher_prefix', 'school_state', 'project_grade_category', 'date', 'after_20160517',\n",
    "                'teacher_number_of_previously_posted_projects', 'project_title_wordcount', \n",
    "                'project_essay_1_wordcount_before', 'project_essay_2_wordcount_before', \n",
    "                'project_essay_3_wordcount_before', 'project_essay_4_wordcount_before', \n",
    "                'project_essay_1_wordcount_after', 'project_essay_2_wordcount_after', \n",
    "                'project_essay_3_wordcount_after', 'project_essay_4_wordcount_after', \n",
    "                'resources_count', 'total_price_sum', 'total_price_max', 'total_price_mean']\n",
    "cols_to_dummify = ['teacher_prefix', 'school_state', 'project_grade_category']\n",
    "cols_to_encode = ['date']\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "# Prep training data\n",
    "\n",
    "X_train = train[nontext_feature_cols]\n",
    "X_train = pd.get_dummies(X_train, columns=cols_to_dummify)\n",
    "X_train[cols_to_encode] = X_train[cols_to_encode].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "X_train = np.hstack((np.array(X_train),\n",
    "                      countvecs_train['project_subject_categories'].toarray(),\n",
    "                      countvecs_train['project_subject_subcategories'].toarray()))\n",
    "y_train = train['project_is_approved']\n",
    "\n",
    "\n",
    "# Prep testing data\n",
    "\n",
    "X_test = test[nontext_feature_cols]\n",
    "X_test = pd.get_dummies(X_test, columns=cols_to_dummify)\n",
    "X_test[cols_to_encode] = X_test[cols_to_encode].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "X_test = np.hstack((np.array(X_test),\n",
    "                      countvecs_test['project_subject_categories'].toarray(),\n",
    "                      countvecs_test['project_subject_subcategories'].toarray()))\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "y_pred_proba_xgb_train = cross_val_predict(xgb_classifier, X_train, y_train, cv=3, method='predict_proba')[:,1]\n",
    "y_pred_proba_xgb_test = xgb_classifier.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Combine predicted probabilities from xgb model with non-text feature with \n",
    "# predicted probabilites from mnb with text features\n",
    "# =========================================================================\n",
    "\n",
    "X_pred_probas_train = pd.Series(y_pred_proba_xgb_train)\n",
    "for col in ['project_essay_3_proba_before', 'project_essay_2_proba_after', 'resource_descriptions_proba']:\n",
    "    X_pred_probas_train = pd.concat([X_pred_probas_train, train[col].reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_pred_probas_test = pd.Series(y_pred_proba_xgb_test)\n",
    "for col in ['project_essay_3_proba_before', 'project_essay_2_proba_after', 'resource_descriptions_proba']:\n",
    "    X_pred_probas_test = pd.concat([X_pred_probas_test, test[col].reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_test_w_probas_test = np.hstack([X_test, X_pred_probas_test])\n",
    "X_test_w_probas_train = np.hstack([X_train, X_pred_probas_train])\n",
    "\n",
    "xgb_classifier.fit(X_test_w_probas_train, y_train)\n",
    "y_pred_proba_final = xgb_classifier.predict_proba(X_test_w_probas_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "timestamp = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H:%M:%S')\n",
    "\n",
    "submission = pd.DataFrame({'id': test['id'], 'project_is_approved': y_pred_proba_final})\n",
    "submission.to_csv('../submissions/submission_{0}.csv'.format(timestamp), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
